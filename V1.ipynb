{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sklearn\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1309 entries, 0 to 417\n",
      "Data columns (total 12 columns):\n",
      "Age            1046 non-null float64\n",
      "Cabin          295 non-null object\n",
      "Embarked       1307 non-null object\n",
      "Fare           1308 non-null float64\n",
      "Name           1309 non-null object\n",
      "Parch          1309 non-null int64\n",
      "PassengerId    1309 non-null int64\n",
      "Pclass         1309 non-null int64\n",
      "Sex            1309 non-null object\n",
      "SibSp          1309 non-null int64\n",
      "Survived       1309 non-null int64\n",
      "Ticket         1309 non-null object\n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 132.9+ KB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\noufal.samsudin\\AppData\\Local\\Continuum\\anaconda3\\envs\\manipalenvname\\lib\\site-packages\\ipykernel_launcher.py:4: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "df=pd.read_csv('./train.csv')\n",
    "dftest=pd.read_csv(\"./test.csv\")\n",
    "dftest[\"Survived\"]=-1\n",
    "df=pd.concat([df,dftest])\n",
    "df.info()\n",
    "# dftest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age 98\n",
      "Cabin 186\n",
      "Embarked 3\n",
      "Fare 281\n",
      "Name 1307\n",
      "Parch 8\n",
      "PassengerId 1309\n",
      "Pclass 3\n",
      "Sex 2\n",
      "SibSp 7\n",
      "Survived 3\n",
      "Ticket 929\n"
     ]
    }
   ],
   "source": [
    "for col in df.columns:\n",
    "    print(col,df[col].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Age', 'Cabin', 'Embarked', 'Fare', 'Name', 'Parch', 'PassengerId',\n",
       "       'Pclass', 'Sex', 'SibSp', 'Survived', 'Ticket'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "S    914\n",
       "C    270\n",
       "Q    123\n",
       "Name: Embarked, dtype: int64"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Embarked'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age             263\n",
       "Cabin          1014\n",
       "Embarked          2\n",
       "Fare              1\n",
       "Name              0\n",
       "Parch             0\n",
       "PassengerId       0\n",
       "Pclass            0\n",
       "Sex               0\n",
       "SibSp             0\n",
       "Survived          0\n",
       "Ticket            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dropcols=['PassengerId','Name']\n",
    "catcols=['Pclass','Sex','Ticket','Cabin','Embarked']\n",
    "num_cols=['Age','SibSp','Parch','Fare']\n",
    "target=['Survived']\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[col].mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age\n",
      "SibSp\n",
      "Parch\n",
      "Fare\n",
      "Pclass\n",
      "Sex\n",
      "Ticket\n",
      "Cabin\n",
      "Embarked\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Age            0\n",
       "Cabin          0\n",
       "Embarked       0\n",
       "Fare           0\n",
       "Name           0\n",
       "Parch          0\n",
       "PassengerId    0\n",
       "Pclass         0\n",
       "Sex            0\n",
       "SibSp          0\n",
       "Survived       0\n",
       "Ticket         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# dfbackup=df.copy()\n",
    "for col in num_cols:\n",
    "    print(col)\n",
    "    df.loc[df[col].isnull(),col]=df[col].median()\n",
    "for col in catcols:\n",
    "    print(col)\n",
    "    df.loc[df[col].isnull(),col]=df[col].mode()[0]\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "looking at Pclass: val count 3\n",
      "looking at Sex: val count 2\n",
      "looking at Ticket: val count 929\n",
      "reducing...\n",
      "looking at Cabin: val count 186\n",
      "reducing...\n",
      "looking at Embarked: val count 3\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "dffeats=pd.DataFrame()\n",
    "for col in catcols:\n",
    "  print(\"looking at {}: val count {}\".format(col,df[col].nunique()))\n",
    "  if (df[col].nunique()>3):\n",
    "    print(\"reducing...\")\n",
    "    freqs=df[col].value_counts()\n",
    "    small_cats=freqs[freqs<3].index\n",
    "    dffeats[col]=df[col].replace(small_cats, 'other')\n",
    "  else:\n",
    "    dffeats[col]=df[col]  \n",
    "  \n",
    "  enc = LabelEncoder()\n",
    "  dffeats[col]=enc.fit_transform(dffeats[col].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age\n",
      "SibSp\n",
      "Parch\n",
      "Fare\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>84</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0.18750</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>84</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0.68750</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.904376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>84</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0.31250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>84</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>0.59375</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.646274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>84</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0.59375</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.006813</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pclass  Sex  Ticket  Cabin  Embarked      Age  SibSp  Parch      Fare\n",
       "0       2    1      84      7         2  0.18750    1.0    0.0  0.000000\n",
       "1       0    0      84     16         0  0.68750    1.0    0.0  0.904376\n",
       "2       2    0      84      7         2  0.31250    0.0    0.0  0.005039\n",
       "3       0    0      84     16         2  0.59375    1.0    0.0  0.646274\n",
       "4       2    1      84      7         2  0.59375    0.0    0.0  0.006813"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "for col in num_cols:\n",
    "  print(col)\n",
    "  dffeats[col]=df[col]\n",
    "  upperlimit=dffeats[col].quantile(.9)\n",
    "  lowerlimit=dffeats[col].quantile(.1)\n",
    "  dffeats.loc[dffeats[col]>upperlimit,col]=upperlimit\n",
    "  dffeats.loc[dffeats[col]<lowerlimit,col]=lowerlimit\n",
    "  scaler=MinMaxScaler()\n",
    "  dffeats[col]=scaler.fit_transform(dffeats[col].values.reshape(-1,1)).flatten()\n",
    "dffeats.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in dropcols+target:\n",
    "    dffeats[col]=df[col]\n",
    "testdata=dffeats[dffeats[target[0]]==-1]\n",
    "traindata=dffeats[dffeats[target[0]]!=-1]\n",
    "X=traindata[num_cols+catcols].values\n",
    "y=traindata[target[0]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('display.max_columns', None)\n",
    "from sklearn.metrics import accuracy_score, log_loss,roc_curve,auc,roc_auc_score,confusion_matrix\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC, LinearSVC, NuSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "# import lightgbm as lgb\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=314,stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\noufal.samsudin\\AppData\\Local\\Continuum\\anaconda3\\envs\\manipalenvname\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\noufal.samsudin\\AppData\\Local\\Continuum\\anaconda3\\envs\\manipalenvname\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\noufal.samsudin\\AppData\\Local\\Continuum\\anaconda3\\envs\\manipalenvname\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\noufal.samsudin\\AppData\\Local\\Continuum\\anaconda3\\envs\\manipalenvname\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\noufal.samsudin\\AppData\\Local\\Continuum\\anaconda3\\envs\\manipalenvname\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "LogisticRegression\n",
      "****Results****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\noufal.samsudin\\AppData\\Local\\Continuum\\anaconda3\\envs\\manipalenvname\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\noufal.samsudin\\AppData\\Local\\Continuum\\anaconda3\\envs\\manipalenvname\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\noufal.samsudin\\AppData\\Local\\Continuum\\anaconda3\\envs\\manipalenvname\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\noufal.samsudin\\AppData\\Local\\Continuum\\anaconda3\\envs\\manipalenvname\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\noufal.samsudin\\AppData\\Local\\Continuum\\anaconda3\\envs\\manipalenvname\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\noufal.samsudin\\AppData\\Local\\Continuum\\anaconda3\\envs\\manipalenvname\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross val score; 0.8518840788840787\n",
      "Training Accuracy: 81.2199%\n",
      "Testing Accuracy: 76.1194%\n",
      "==============================\n",
      "KNeighborsClassifier\n",
      "****Results****\n",
      "Cross val score; 0.802751181280593\n",
      "Training Accuracy: 86.0353%\n",
      "Testing Accuracy: 78.3582%\n",
      "==============================\n",
      "KNeighborsClassifier\n",
      "****Results****\n",
      "Cross val score; 0.8217342330871741\n",
      "Training Accuracy: 79.9358%\n",
      "Testing Accuracy: 80.9701%\n",
      "==============================\n",
      "KNeighborsClassifier\n",
      "****Results****\n",
      "Cross val score; 0.818849418555301\n",
      "Training Accuracy: 78.6517%\n",
      "Testing Accuracy: 78.3582%\n",
      "==============================\n",
      "KNeighborsClassifier\n",
      "****Results****\n",
      "Cross val score; 0.8176287808052514\n",
      "Training Accuracy: 75.9230%\n",
      "Testing Accuracy: 74.6269%\n",
      "==============================\n",
      "DecisionTreeClassifier\n",
      "****Results****\n",
      "Cross val score; 0.7686627054862349\n",
      "Training Accuracy: 97.7528%\n",
      "Testing Accuracy: 76.8657%\n",
      "==============================\n",
      "RandomForestClassifier\n",
      "****Results****\n",
      "Cross val score; 0.8640182214299861\n",
      "Training Accuracy: 97.7528%\n",
      "Testing Accuracy: 77.2388%\n",
      "==============================\n",
      "AdaBoostClassifier\n",
      "****Results****\n",
      "Cross val score; 0.8519869281045752\n",
      "Training Accuracy: 83.7881%\n",
      "Testing Accuracy: 78.3582%\n",
      "==============================\n",
      "GradientBoostingClassifier\n",
      "****Results****\n",
      "Cross val score; 0.8764741815918287\n",
      "Training Accuracy: 91.1717%\n",
      "Testing Accuracy: 81.3433%\n",
      "==============================\n",
      "GaussianNB\n",
      "****Results****\n",
      "Cross val score; 0.800282969753558\n",
      "Training Accuracy: 75.4414%\n",
      "Testing Accuracy: 72.3881%\n",
      "==============================\n",
      "LinearDiscriminantAnalysis\n",
      "****Results****\n",
      "Cross val score; 0.8551519961519961\n",
      "Training Accuracy: 81.3804%\n",
      "Testing Accuracy: 75.3731%\n",
      "==============================\n",
      "QuadraticDiscriminantAnalysis\n",
      "****Results****\n",
      "Cross val score; 0.8443235435588375\n",
      "Training Accuracy: 80.0963%\n",
      "Testing Accuracy: 78.3582%\n"
     ]
    }
   ],
   "source": [
    "classifiers = [\n",
    "    LogisticRegression(),\n",
    "    KNeighborsClassifier(3),\n",
    "    KNeighborsClassifier(9),\n",
    "    KNeighborsClassifier(27),\n",
    "    KNeighborsClassifier(51),\n",
    "    DecisionTreeClassifier(),\n",
    "    RandomForestClassifier(),\n",
    "    AdaBoostClassifier(),\n",
    "    GradientBoostingClassifier(),\n",
    "    GaussianNB(),\n",
    "    LinearDiscriminantAnalysis(),\n",
    "    QuadraticDiscriminantAnalysis()]\n",
    "\n",
    "# Logging for Visual Comparison\n",
    "\n",
    "for clf in classifiers:\n",
    "    \n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    name = clf.__class__.__name__\n",
    "    \n",
    "    print(\"=\"*30)\n",
    "    print(name)\n",
    "    print('****Results****')\n",
    "    print(\"Cross val score; {}\".format(np.mean(cross_val_score(clf, X, y, cv=10, scoring='roc_auc'))))\n",
    "    cat_train_predictions = clf.predict(X_test)\n",
    "    acc = accuracy_score(y_test, cat_train_predictions)\n",
    "    print(\"Training Accuracy: {:.4%}\".format(accuracy_score(y_train,clf.predict(X_train))))\n",
    "    print(\"Testing Accuracy: {:.4%}\".format(acc))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\noufal.samsudin\\AppData\\Local\\Continuum\\anaconda3\\envs\\manipalenvname\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Name</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>84</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0.578125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003679</td>\n",
       "      <td>892</td>\n",
       "      <td>Kelly, Mr. James</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>84</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0.968750</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>893</td>\n",
       "      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>84</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.030057</td>\n",
       "      <td>894</td>\n",
       "      <td>Myles, Mr. Thomas Francis</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>84</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0.343750</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.015507</td>\n",
       "      <td>895</td>\n",
       "      <td>Wirz, Mr. Albert</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>84</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.066962</td>\n",
       "      <td>896</td>\n",
       "      <td>Hirvonen, Mrs. Alexander (Helga E Lindqvist)</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pclass  Sex  Ticket  Cabin  Embarked       Age  SibSp  Parch      Fare  \\\n",
       "0       2    1      84      7         1  0.578125    0.0    0.0  0.003679   \n",
       "1       2    0      84      7         2  0.968750    1.0    0.0  0.000000   \n",
       "2       1    1      84      7         1  1.000000    0.0    0.0  0.030057   \n",
       "3       2    1      84      7         2  0.343750    0.0    0.0  0.015507   \n",
       "4       2    0      84      7         2  0.187500    1.0    0.5  0.066962   \n",
       "\n",
       "   PassengerId                                          Name  Survived  \n",
       "0          892                              Kelly, Mr. James         0  \n",
       "1          893              Wilkes, Mrs. James (Ellen Needs)         0  \n",
       "2          894                     Myles, Mr. Thomas Francis         0  \n",
       "3          895                              Wirz, Mr. Albert         0  \n",
       "4          896  Hirvonen, Mrs. Alexander (Helga E Lindqvist)         0  "
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output=classifiers[-1].predict(testdata[num_cols+catcols].values)\n",
    "testdata[\"Survived\"]=output\n",
    "testdata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testdata[[\"PassengerId\",\"Survived\"]].to_csv(\"QDAoutput.csv\",index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "votingC = VotingClassifier(estimators=\n",
    "[(\"{}_{}\".format(i,clf.__class__.__name__ ),clf) for i,clf in enumerate(classifiers)], voting='soft', n_jobs=4)\n",
    "\n",
    "votingC = votingC.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross val score; 0.866873864697394\n"
     ]
    }
   ],
   "source": [
    "print(\"Cross val score; {}\".format(np.mean(cross_val_score(votingC, X, y, cv=10, scoring='roc_auc'))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\noufal.samsudin\\AppData\\Local\\Continuum\\anaconda3\\envs\\manipalenvname\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "output=votingC.predict(testdata[num_cols+catcols].values)\n",
    "testdata[\"Survived\"]=output\n",
    "testdata[[\"PassengerId\",\"Survived\"]].to_csv(\"Voringoutliernoutput.csv\",index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

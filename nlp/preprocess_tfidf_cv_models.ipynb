{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing, decomposition, model_selection, metrics, pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report,roc_auc_score,f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train= pd.read_csv('./nlp-getting-started/train.csv')\n",
    "test=pd.read_csv('./nlp-getting-started/test.csv')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7613, 5)\n",
      "keyword column nunique 221\n",
      "keyword column val counts {nan: 0.8012610009194797, 'fatalities': 0.5910941810061737, 'deluge': 0.5516879022724287, 'armageddon': 0.5516879022724287, 'body%20bags': 0.5385524760278472, 'harm': 0.5385524760278472, 'sinking': 0.5385524760278472}\n",
      "location column nunique 3341\n",
      "location column val counts {nan: 33.27203467752528, 'USA': 1.3660843294364904, 'New York': 0.9326152633652962, 'United States': 0.6567713122290818, 'London': 0.5910941810061737, 'Canada': 0.38092736109286746, 'Nigeria': 0.3677919348482858}\n",
      "target column nunique 2\n",
      "target column val counts {0: 57.03402075397347, 1: 42.96597924602653}\n"
     ]
    }
   ],
   "source": [
    "print(train.shape)\n",
    "train.isnull().sum()\n",
    "train.columns\n",
    "for col in ['keyword', 'location','target']:\n",
    "    print(\"{} column nunique {}\".format(col,train[col].nunique()))\n",
    "    print(\"{} column val counts {}\".format(col,(train[col].value_counts(normalize=True,dropna=False)*100).head(7).to_dict()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6851,) (762,) (6851,) (762,) (3263,)\n"
     ]
    }
   ],
   "source": [
    "xtrain, xvalid, ytrain, yvalid = train_test_split(train.text.values, train.target.values, \n",
    "                                                  stratify=train.target.values, \n",
    "                                                  random_state=42, \n",
    "                                                  test_size=0.1, shuffle=True)\n",
    "xtest=test.text.values\n",
    "\n",
    "print(xtrain.shape, xvalid.shape, ytrain.shape, yvalid.shape,xtest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfv = TfidfVectorizer(min_df=3,  max_features=None, \n",
    "            strip_accents='unicode', analyzer='word',token_pattern=r'\\w{1,}',\n",
    "            ngram_range=(1, 3), use_idf=1,smooth_idf=1,sublinear_tf=1,\n",
    "            stop_words = 'english')\n",
    "\n",
    "\n",
    "tfv.fit(list(xtrain) + list(xvalid)+ list(xtest))\n",
    "xtrain_tfv =  tfv.transform(xtrain) \n",
    "xvalid_tfv = tfv.transform(xvalid)\n",
    "xtest_tfv=tfv.transform(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\noufal.samsudin\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\noufal.samsudin\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression score: 0.8700411262258779\n",
      "RandomForestClassifier score: 0.8183556539772928\n"
     ]
    }
   ],
   "source": [
    "for clf in [LogisticRegression(C=1.0),RandomForestClassifier()]:\n",
    "# clf = LogisticRegression(C=1.0)\n",
    "    clf.fit(xtrain_tfv, ytrain)\n",
    "    predictions = clf.predict_proba(xvalid_tfv)\n",
    "    # print(classification_report(predictions,yvalid))\n",
    "    score=roc_auc_score(yvalid,predictions[:,1])\n",
    "    print(\"{} score: {}\".format(clf.__class__.__name__,score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression score: 0.8700411262258779\n",
      "threshold 0.1 score: 0.6038781163434903\n",
      "threshold 0.15000000000000002 score: 0.6143667296786389\n",
      "threshold 0.20000000000000004 score: 0.6510204081632653\n",
      "threshold 0.25000000000000006 score: 0.6814159292035399\n",
      "threshold 0.30000000000000004 score: 0.7139423076923076\n",
      "threshold 0.3500000000000001 score: 0.75\n",
      "threshold 0.40000000000000013 score: 0.7576197387518142\n",
      "threshold 0.45000000000000007 score: 0.7774294670846396\n",
      "threshold 0.5000000000000001 score: 0.7529411764705881\n",
      "threshold 0.5500000000000002 score: 0.7289048473967685\n",
      "threshold 0.6000000000000002 score: 0.6994328922495274\n",
      "threshold 0.6500000000000001 score: 0.6345381526104418\n",
      "threshold 0.7000000000000002 score: 0.5219298245614036\n",
      "threshold 0.7500000000000002 score: 0.43294117647058816\n",
      "threshold 0.8000000000000002 score: 0.31632653061224486\n",
      "threshold 0.8500000000000002 score: 0.20821917808219179\n",
      "threshold 0.9000000000000002 score: 0.08211143695014662\n",
      "threshold 0.9500000000000003 score: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\noufal.samsudin\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\noufal.samsudin\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "clf=LogisticRegression(C=1.0)\n",
    "clf.fit(xtrain_tfv, ytrain)\n",
    "predictions = clf.predict_proba(xvalid_tfv)\n",
    "score=roc_auc_score(yvalid,predictions[:,1])\n",
    "print(\"{} score: {}\".format(clf.__class__.__name__,score))\n",
    "# test[\"predict_lr_tfidf1\"]=\n",
    "thresholds=np.arange(0.1,1,0.05)\n",
    "for threshold in thresholds:\n",
    "    temp=predictions[:,1].copy()\n",
    "    temp[temp>=threshold]=1\n",
    "    temp[temp<threshold]=0\n",
    "    score=f1_score(yvalid,temp)\n",
    "    print(\"threshold {} score: {}\".format(threshold,score))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>pred1_tfidf_lr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just happened a terrible car crash</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Heard about #earthquake is different cities, s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>there is a forest fire at spot pond, geese are...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   0     NaN      NaN                 Just happened a terrible car crash   \n",
       "1   2     NaN      NaN  Heard about #earthquake is different cities, s...   \n",
       "2   3     NaN      NaN  there is a forest fire at spot pond, geese are...   \n",
       "3   9     NaN      NaN           Apocalypse lighting. #Spokane #wildfires   \n",
       "4  11     NaN      NaN      Typhoon Soudelor kills 28 in China and Taiwan   \n",
       "\n",
       "   pred1_tfidf_lr  \n",
       "0               1  \n",
       "1               0  \n",
       "2               1  \n",
       "3               1  \n",
       "4               1  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threshold=0.5\n",
    "testpred=clf.predict_proba(xtest_tfv)\n",
    "testpred=testpred[:,1].copy()\n",
    "testpred[testpred>=threshold]=1\n",
    "testpred[testpred<threshold]=0\n",
    "test[\"pred1_tfidf_lr\"]=testpred\n",
    "test[\"pred1_tfidf_lr\"]=test[\"pred1_tfidf_lr\"].astype(int)\n",
    "test[[\"id\",\"pred1_tfidf_lr\"]].rename(columns={\"pred1_tfidf_lr\":\"target\"}).to_csv(\"./submissions/submission_1.csv\",index=None)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\noufal.samsudin\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression score: 0.8612815916200921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\noufal.samsudin\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier score: 0.8416991809905445\n"
     ]
    }
   ],
   "source": [
    "# Trying same with count vevtorizer\n",
    "ctv = CountVectorizer(analyzer='word',token_pattern=r'\\w{1,}',\n",
    "            ngram_range=(1, 3), stop_words = 'english')\n",
    "\n",
    "\n",
    "ctv.fit(list(xtrain) + list(xvalid)+ list(xtest))\n",
    "xtrain_ctv =  ctv.transform(xtrain) \n",
    "xvalid_ctv = ctv.transform(xvalid)\n",
    "xtest_ctv=ctv.transform(xtest)\n",
    "for clf in [LogisticRegression(C=1.0),RandomForestClassifier()]:\n",
    "# clf = LogisticRegression(C=1.0)\n",
    "    clf.fit(xtrain_ctv, ytrain)\n",
    "    predictions = clf.predict_proba(xvalid_ctv)\n",
    "    # print(classification_report(predictions,yvalid))\n",
    "    score=roc_auc_score(yvalid,predictions[:,1])\n",
    "    print(\"{} score: {}\".format(clf.__class__.__name__,score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\noufal.samsudin\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression score: 0.8612815916200921\n",
      "threshold 0.1 score: 0.6702470461868958\n",
      "threshold 0.15000000000000002 score: 0.7058823529411764\n",
      "threshold 0.20000000000000004 score: 0.7302798982188294\n",
      "threshold 0.25000000000000006 score: 0.7381275440976934\n",
      "threshold 0.30000000000000004 score: 0.757532281205165\n",
      "threshold 0.3500000000000001 score: 0.7671641791044775\n",
      "threshold 0.40000000000000013 score: 0.7580893682588598\n",
      "threshold 0.45000000000000007 score: 0.7548387096774194\n",
      "threshold 0.5000000000000001 score: 0.7373737373737373\n",
      "threshold 0.5500000000000002 score: 0.7247386759581883\n",
      "threshold 0.6000000000000002 score: 0.7198581560283689\n",
      "threshold 0.6500000000000001 score: 0.7150635208711434\n",
      "threshold 0.7000000000000002 score: 0.6902985074626865\n",
      "threshold 0.7500000000000002 score: 0.6718146718146718\n",
      "threshold 0.8000000000000002 score: 0.6234817813765183\n",
      "threshold 0.8500000000000002 score: 0.5970772442588727\n",
      "threshold 0.9000000000000002 score: 0.5122494432071268\n",
      "threshold 0.9500000000000003 score: 0.4144578313253012\n"
     ]
    }
   ],
   "source": [
    "clf=LogisticRegression(C=1.0)\n",
    "clf.fit(xtrain_ctv, ytrain)\n",
    "predictions = clf.predict_proba(xvalid_ctv)\n",
    "score=roc_auc_score(yvalid,predictions[:,1])\n",
    "print(\"{} score: {}\".format(clf.__class__.__name__,score))\n",
    "# test[\"predict_lr_tfidf1\"]=\n",
    "thresholds=np.arange(0.1,1,0.05)\n",
    "for threshold in thresholds:\n",
    "    temp=predictions[:,1].copy()\n",
    "    temp[temp>=threshold]=1\n",
    "    temp[temp<threshold]=0\n",
    "    score=f1_score(yvalid,temp)\n",
    "    print(\"threshold {} score: {}\".format(threshold,score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>pred1_tfidf_lr</th>\n",
       "      <th>pred1_ctv_lr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just happened a terrible car crash</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Heard about #earthquake is different cities, s...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>there is a forest fire at spot pond, geese are...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   0     NaN      NaN                 Just happened a terrible car crash   \n",
       "1   2     NaN      NaN  Heard about #earthquake is different cities, s...   \n",
       "2   3     NaN      NaN  there is a forest fire at spot pond, geese are...   \n",
       "3   9     NaN      NaN           Apocalypse lighting. #Spokane #wildfires   \n",
       "4  11     NaN      NaN      Typhoon Soudelor kills 28 in China and Taiwan   \n",
       "\n",
       "   pred1_tfidf_lr  pred1_ctv_lr  \n",
       "0               1             1  \n",
       "1               0             1  \n",
       "2               1             1  \n",
       "3               1             0  \n",
       "4               1             1  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threshold=0.35\n",
    "testpred=clf.predict_proba(xtest_ctv)\n",
    "testpred=testpred[:,1].copy()\n",
    "testpred[testpred>=threshold]=1\n",
    "testpred[testpred<threshold]=0\n",
    "test[\"pred1_ctv_lr\"]=testpred\n",
    "test[\"pred1_ctv_lr\"]=test[\"pred1_ctv_lr\"].astype(int)\n",
    "test[[\"id\",\"pred1_ctv_lr\"]].rename(columns={\"pred1_ctv_lr\":\"target\"}).to_csv(\"./submissions/submission_2.csv\",index=None)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, log_loss,roc_curve,auc,roc_auc_score,confusion_matrix\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC, LinearSVC, NuSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "# import lightgbm as lgb\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# !pip install xgboost\n",
    "import xgboost as xgb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TFIDF vectorizerXGBClassifier mean score 0.7252999295160576 std 0.012088962861161096\n",
      "Count vectorizerXGBClassifier mean score 0.7222360447061843 std 0.021705400426741833\n"
     ]
    }
   ],
   "source": [
    "classifiers = [\n",
    "#     LogisticRegression(),\n",
    "#     KNeighborsClassifier(3),\n",
    "#     KNeighborsClassifier(9),\n",
    "#     KNeighborsClassifier(27),\n",
    "#     KNeighborsClassifier(51),\n",
    "#     DecisionTreeClassifier(),\n",
    "#     RandomForestClassifier(),\n",
    "#     AdaBoostClassifier(),\n",
    "#     GaussianNB(),\n",
    "#     LinearDiscriminantAnalysis(),\n",
    "#     QuadraticDiscriminantAnalysis(),\n",
    "    xgb.XGBClassifier(objective=\"binary:logistic\", random_state=42),\n",
    "]\n",
    "for clf in classifiers:\n",
    "    scores=cross_val_score(clf, xtrain_tfv, ytrain, cv=5)\n",
    "    print(\"TFIDF vectorizer{} mean score {} std {}\".format(clf.__class__.__name__,np.mean(scores),np.std(scores)))\n",
    "    scores=cross_val_score(clf, xtrain_ctv, ytrain, cv=5)\n",
    "    print(\"Count vectorizer{} mean score {} std {}\".format(clf.__class__.__name__,np.mean(scores),np.std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6851, 12740)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(xtrain_tfv.shape)\n",
    "# list(xtrain_tfv)+list(xvalid_tfv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing, decomposition, model_selection, metrics, pipeline\n",
    "# Apply SVD, I chose 120 components. 120-200 components are good enough for SVM model.\n",
    "svd = decomposition.TruncatedSVD(n_components=120)\n",
    "svd.fit(xtrain_tfv)\n",
    "xtrain_svd = svd.transform(xtrain_tfv)\n",
    "xvalid_svd = svd.transform(xvalid_tfv)\n",
    "xtest_svd = svd.transform(xtest_tfv)\n",
    "\n",
    "# Scale the data obtained from SVD. Renaming variable to reuse without scaling.\n",
    "scl = preprocessing.StandardScaler()\n",
    "scl.fit(xtrain_svd)\n",
    "xtrain_svd_scl = scl.transform(xtrain_svd)\n",
    "xvalid_svd_scl = scl.transform(xvalid_svd)\n",
    "xtest_svd_scl = scl.transform(xtest_svd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC score: 0.8215438152483392\n"
     ]
    }
   ],
   "source": [
    "clf = SVC(C=1.0, probability=True) # since we need probabilities\n",
    "clf.fit(xtrain_svd_scl, ytrain)\n",
    "predictions = clf.predict_proba(xvalid_svd_scl)\n",
    "score=roc_auc_score(yvalid,predictions[:,1])\n",
    "print(\"{} score: {}\".format(clf.__class__.__name__,score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier score: 0.8466940841505852\n"
     ]
    }
   ],
   "source": [
    "# Fitting a simple xgboost on tf-idf\n",
    "clf = xgb.XGBClassifier(max_depth=7, n_estimators=200, colsample_bytree=0.8, \n",
    "                        subsample=0.8, nthread=10, learning_rate=0.1)\n",
    "clf.fit(xtrain_tfv.tocsc(), ytrain)\n",
    "predictions = clf.predict_proba(xvalid_tfv.tocsc())\n",
    "score=roc_auc_score(yvalid,predictions[:,1])\n",
    "print(\"{} score: {}\".format(clf.__class__.__name__,score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier score: 0.8602481633800837\n"
     ]
    }
   ],
   "source": [
    "# Fitting a simple xgboost on cv\n",
    "clf = xgb.XGBClassifier(max_depth=7, n_estimators=200, colsample_bytree=0.8, \n",
    "                        subsample=0.8, nthread=10, learning_rate=0.1)\n",
    "clf.fit(xtrain_ctv.tocsc(), ytrain)\n",
    "predictions = clf.predict_proba(xvalid_ctv.tocsc())\n",
    "score=roc_auc_score(yvalid,predictions[:,1])\n",
    "print(\"{} score: {}\".format(clf.__class__.__name__,score))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier score: 0.8258146156279659\n"
     ]
    }
   ],
   "source": [
    "# Fitting a simple xgboost on tf-idf svd features\n",
    "clf = xgb.XGBClassifier(max_depth=7, n_estimators=200, colsample_bytree=0.8, \n",
    "                        subsample=0.8, nthread=10, learning_rate=0.1)\n",
    "clf.fit(xtrain_svd, ytrain)\n",
    "predictions = clf.predict_proba(xvalid_svd)\n",
    "\n",
    "score=roc_auc_score(yvalid,predictions[:,1])\n",
    "print(\"{} score: {}\".format(clf.__class__.__name__,score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier score: 0.8191992688670955\n"
     ]
    }
   ],
   "source": [
    "# Fitting a simple xgboost on tf-idf svd features\n",
    "clf = xgb.XGBClassifier(nthread=10)\n",
    "clf.fit(xtrain_svd, ytrain)\n",
    "predictions = clf.predict_proba(xvalid_svd)\n",
    "score=roc_auc_score(yvalid,predictions[:,1])\n",
    "print(\"{} score: {}\".format(clf.__class__.__name__,score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>pred1_tfidf_lr</th>\n",
       "      <th>pred1_ctv_lr</th>\n",
       "      <th>pred1_ctv_xg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just happened a terrible car crash</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Heard about #earthquake is different cities, s...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>there is a forest fire at spot pond, geese are...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   0     NaN      NaN                 Just happened a terrible car crash   \n",
       "1   2     NaN      NaN  Heard about #earthquake is different cities, s...   \n",
       "2   3     NaN      NaN  there is a forest fire at spot pond, geese are...   \n",
       "3   9     NaN      NaN           Apocalypse lighting. #Spokane #wildfires   \n",
       "4  11     NaN      NaN      Typhoon Soudelor kills 28 in China and Taiwan   \n",
       "\n",
       "   pred1_tfidf_lr  pred1_ctv_lr  pred1_ctv_xg  \n",
       "0               1             1             0  \n",
       "1               0             1             1  \n",
       "2               1             1             1  \n",
       "3               1             0             0  \n",
       "4               1             1             1  "
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Revisitng best model above== .86\n",
    "# Fitting a simple xgboost on cv\n",
    "clf = xgb.XGBClassifier(max_depth=7, n_estimators=200, colsample_bytree=0.8, \n",
    "                        subsample=0.8, nthread=10, learning_rate=0.1)\n",
    "clf.fit(xtrain_ctv.tocsc(), ytrain)\n",
    "predictions = clf.predict_proba(xvalid_ctv.tocsc())\n",
    "score=roc_auc_score(yvalid,predictions[:,1])\n",
    "print(\"{} score: {}\".format(clf.__class__.__name__,score))\n",
    "thresholds=np.arange(0.1,1,0.05)\n",
    "for threshold in thresholds:\n",
    "    temp=predictions[:,1].copy()\n",
    "    temp[temp>=threshold]=1\n",
    "    temp[temp<threshold]=0\n",
    "    score=f1_score(yvalid,temp)\n",
    "    print(\"threshold {} score: {}\".format(threshold,score))\n",
    "threshold=0.4\n",
    "testpred=clf.predict_proba(xtest_ctv.tocsc())\n",
    "testpred=testpred[:,1].copy()\n",
    "testpred[testpred>=threshold]=1\n",
    "testpred[testpred<threshold]=0\n",
    "test[\"pred1_ctv_xg\"]=testpred\n",
    "test[\"pred1_ctv_xg\"]=test[\"pred1_ctv_xg\"].astype(int)\n",
    "test[[\"id\",\"pred1_ctv_xg\"]].rename(columns={\"pred1_ctv_xg\":\"target\"}).to_csv(\"./submissions/submission_3.csv\",index=None)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 12 candidates, totalling 24 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    3.9s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    7.5s\n",
      "[Parallel(n_jobs=-1)]: Done  12 out of  24 | elapsed:    9.4s remaining:    9.4s\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  24 | elapsed:   11.2s remaining:    6.7s\n",
      "[Parallel(n_jobs=-1)]: Done  18 out of  24 | elapsed:   11.9s remaining:    3.9s\n",
      "[Parallel(n_jobs=-1)]: Done  21 out of  24 | elapsed:   13.8s remaining:    1.9s\n",
      "[Parallel(n_jobs=-1)]: Done  24 out of  24 | elapsed:   14.7s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  24 out of  24 | elapsed:   14.7s finished\n",
      "C:\\Users\\noufal.samsudin\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.820\n",
      "Best parameters set:\n",
      "\tlr__C: 10\n",
      "\tlr__penalty: 'l2'\n",
      "\tsvd__n_components: 180\n"
     ]
    }
   ],
   "source": [
    "svd = TruncatedSVD()\n",
    "    \n",
    "# Initialize the standard scaler \n",
    "scl = preprocessing.StandardScaler()\n",
    "\n",
    "# We will use logistic regression here..\n",
    "lr_model = LogisticRegression()\n",
    "\n",
    "# Create the pipeline \n",
    "clf = pipeline.Pipeline([('svd', svd),\n",
    "                         ('scl', scl),\n",
    "                         ('lr', lr_model)])\n",
    "param_grid = {'svd__n_components' : [120, 180],\n",
    "              'lr__C': [0.1, 1.0, 10], \n",
    "              'lr__penalty': ['l1', 'l2']}\n",
    "# Initialize Grid Search Model\n",
    "model = GridSearchCV(estimator=clf, param_grid=param_grid, scoring='roc_auc',\n",
    "                                 verbose=10, n_jobs=-1, iid=True, refit=True, cv=2)\n",
    "\n",
    "# Fit Grid Search Model\n",
    "model.fit(xtrain_tfv, ytrain)  # we can use the full data here but im only using xtrain\n",
    "print(\"Best score: %0.3f\" % model.best_score_)\n",
    "print(\"Best parameters set:\")\n",
    "best_parameters = model.best_estimator_.get_params()\n",
    "for param_name in sorted(param_grid.keys()):\n",
    "    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 6 candidates, totalling 12 fits\n",
      "Best score: 0.838\n",
      "Best parameters set:\n",
      "\tnb__alpha: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0479s.) Setting batch_size=8.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of  12 | elapsed:    0.0s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  12 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  12 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   9 out of  12 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  12 out of  12 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "nb_model = MultinomialNB()\n",
    "\n",
    "# Create the pipeline \n",
    "clf = pipeline.Pipeline([('nb', nb_model)])\n",
    "\n",
    "# parameter grid\n",
    "param_grid = {'nb__alpha': [0.001, 0.01, 0.1, 1, 10, 100]}\n",
    "\n",
    "# Initialize Grid Search Model\n",
    "model = GridSearchCV(estimator=clf, param_grid=param_grid, scoring='roc_auc',\n",
    "                                 verbose=10, n_jobs=-1, iid=True, refit=True, cv=2)\n",
    "\n",
    "# Fit Grid Search Model\n",
    "model.fit(xtrain_tfv, ytrain)  # we can use the full data here but im only using xtrain. \n",
    "print(\"Best score: %0.3f\" % model.best_score_)\n",
    "print(\"Best parameters set:\")\n",
    "best_parameters = model.best_estimator_.get_params()\n",
    "for param_name in sorted(param_grid.keys()):\n",
    "    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline score: 0.8585539034763963\n",
      "threshold 0.1 score: 0.6352705410821644\n",
      "threshold 0.15000000000000002 score: 0.6695938529088913\n",
      "threshold 0.20000000000000004 score: 0.7091346153846153\n",
      "threshold 0.25000000000000006 score: 0.7303664921465969\n",
      "threshold 0.30000000000000004 score: 0.7613636363636362\n",
      "threshold 0.3500000000000001 score: 0.7617602427921092\n",
      "threshold 0.40000000000000013 score: 0.7472178060413355\n",
      "threshold 0.45000000000000007 score: 0.734006734006734\n",
      "threshold 0.5000000000000001 score: 0.7155322862129145\n",
      "threshold 0.5500000000000002 score: 0.707182320441989\n",
      "threshold 0.6000000000000002 score: 0.6969696969696969\n",
      "threshold 0.6500000000000001 score: 0.6547619047619047\n",
      "threshold 0.7000000000000002 score: 0.6229508196721312\n",
      "threshold 0.7500000000000002 score: 0.5622317596566524\n",
      "threshold 0.8000000000000002 score: 0.52\n",
      "threshold 0.8500000000000002 score: 0.4522144522144522\n",
      "threshold 0.9000000000000002 score: 0.36543209876543203\n",
      "threshold 0.9500000000000003 score: 0.30848329048843187\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>pred1_tfidf_lr</th>\n",
       "      <th>pred1_ctv_lr</th>\n",
       "      <th>pred1_ctv_xg</th>\n",
       "      <th>pred1_tfv_mnb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just happened a terrible car crash</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Heard about #earthquake is different cities, s...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>there is a forest fire at spot pond, geese are...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   0     NaN      NaN                 Just happened a terrible car crash   \n",
       "1   2     NaN      NaN  Heard about #earthquake is different cities, s...   \n",
       "2   3     NaN      NaN  there is a forest fire at spot pond, geese are...   \n",
       "3   9     NaN      NaN           Apocalypse lighting. #Spokane #wildfires   \n",
       "4  11     NaN      NaN      Typhoon Soudelor kills 28 in China and Taiwan   \n",
       "\n",
       "   pred1_tfidf_lr  pred1_ctv_lr  pred1_ctv_xg  pred1_tfv_mnb  \n",
       "0               1             1             0              1  \n",
       "1               0             1             1              1  \n",
       "2               1             1             1              1  \n",
       "3               1             0             0              1  \n",
       "4               1             1             1              1  "
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = model.best_estimator_\n",
    "clf.fit(xtrain_tfv, ytrain)\n",
    "predictions = clf.predict_proba(xvalid_tfv)\n",
    "score=roc_auc_score(yvalid,predictions[:,1])\n",
    "print(\"{} score: {}\".format(clf.__class__.__name__,score))\n",
    "thresholds=np.arange(0.1,1,0.05)\n",
    "for threshold in thresholds:\n",
    "    temp=predictions[:,1].copy()\n",
    "    temp[temp>=threshold]=1\n",
    "    temp[temp<threshold]=0\n",
    "    score=f1_score(yvalid,temp)\n",
    "    print(\"threshold {} score: {}\".format(threshold,score))\n",
    "threshold=0.3\n",
    "testpred=clf.predict_proba(xtest_tfv)\n",
    "testpred=testpred[:,1].copy()\n",
    "testpred[testpred>=threshold]=1\n",
    "testpred[testpred<threshold]=0\n",
    "test[\"pred1_tfv_mnb\"]=testpred\n",
    "test[\"pred1_tfv_mnb\"]=test[\"pred1_tfv_mnb\"].astype(int)\n",
    "test[[\"id\",\"pred1_tfv_mnb\"]].rename(columns={\"pred1_tfv_mnb\":\"target\"}).to_csv(\"./submissions/submission_4.csv\",index=None)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
